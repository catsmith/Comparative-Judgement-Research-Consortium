
@article{pelechrinis_anatomy_2016,
	title = {The anatomy of american football: Evidence from 7 Years of {NFL} game data},
	volume = {11},
	url = {https://lens.org/111-362-703-956-643},
	doi = {10.1371/journal.pone.0168716},
	pages = {e0168716--},
	number = {12},
	journaltitle = {{PloS} one},
	author = {Pelechrinis, Konstantinos and Papalexakis, Evangelos E.},
	date = {2016-12-22},
}

@article{coertjens_improving_2021,
	title = {Improving self-reflection assessment practices: Comparative judgment as an alternative to rubrics},
	volume = {33},
	url = {https://lens.org/103-951-437-485-96X},
	doi = {10.1080/10401334.2021.1877709},
	pages = {525--535},
	number = {5},
	journaltitle = {Teaching and learning in Medicine},
	author = {Coertjens, Liesje and Lesterhuis, Marije and Winter, Benedicte Y. De and Goossens, Maarten and Maeyer, Sven De and Michels, Nele R. M.},
	date = {2021-02-11},
}

@article{jones_fifty_2016,
	title = {Fifty years of A‐level mathematics: have standards changed?},
	volume = {42},
	url = {https://doi.org/10.1002/berj.3224},
	doi = {10.1002/berj.3224},
	pages = {543--560},
	number = {4},
	journaltitle = {British Educational Research Journal},
	author = {Jones, Ian and Wheadon, Chris and Humphries, Sara M. and Inglis, Matthew},
	date = {2016-02-18},
}

@article{jones_visual_2020,
	title = {The visual complexity of coronal mass ejections follows the solar cycle},
	volume = {18},
	issn = {1542-7390},
	url = {https://doi.org/10.1029/2020SW002556},
	doi = {10.1029/2020SW002556},
	abstract = {Abstract The Heliospheric Imagers on board National Aeronautics and Space Administration ({NASA})'s twin {STEREO} spacecraft show that coronal mass ejections ({CMEs}) can be visually complex structures. To explore this complexity, we created a citizen science project with the U.K. Science Museum, in which participants were shown pairs of {CME} images and asked to decide which image in each pair appeared the most ?complicated.? A Bradley-Terry model was then applied to these data to rank the {CMEs} by their ?complicatedness,? or ?visual complexity.? This complexity ranking revealed that the annual average visual complexity values follow the solar activity cycle, with a higher level of complexity being observed at the peak of the cycle. The average complexity of {CMEs} observed by {STEREO}-A was also found to be significantly higher than those observed by {STEREO}-B. Visual complexity was found to be associated with {CME} size and brightness, but our results suggest that complexity may be influenced by the scale-sizes of structure in the {CMEs}.},
	pages = {e2020SW002556},
	number = {10},
	journaltitle = {Space Weather},
	shortjournal = {Space Weather},
	author = {Jones, S. R. and Scott, C. J. and Barnard, L. A. and Highfield, R. and Lintott, C. J. and Baeten, E.},
	urldate = {2021-09-09},
	date = {2020-10-01},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {citizen science, coronal mass ejections, solar cycle},
}

@article{holmes_investigation_2017,
	title = {An investigation of construct relevant and irrelevant features of mathematics problem-solving questions using comparative judgement and Kelly’s Repertory Grid},
	volume = {19},
	url = {https://doi.org/10.1080/14794802.2017.1334576},
	doi = {10.1080/14794802.2017.1334576},
	pages = {112--129},
	number = {2},
	journaltitle = {Research in Mathematics Education},
	author = {Holmes, Stephen D. and He, Qingping and Meadows, Michelle},
	date = {2017},
}

@article{holmes_investigating_2018,
	title = {Investigating the comparability of examination difficulty using comparative judgement and Rasch modelling},
	volume = {18},
	url = {https://doi.org/10.1080/15305058.2018.1486316},
	doi = {10.1080/15305058.2018.1486316},
	pages = {366--391},
	journaltitle = {International Journal of Testing},
	author = {Holmes, Stephen D. and Meadows, Michelle and Stockford, Ian and He, Qingping},
	date = {2018},
}

@article{braun_using_2006,
	title = {Using thematic analysis in psychology},
	volume = {3},
	url = {https://www.tandfonline.com/doi/abs/10.1191/1478088706qp063oa},
	doi = {10.1191/1478088706qp063oa},
	pages = {77--101},
	journaltitle = {Qualitative Research in Psychology},
	author = {Braun, Virginia and Clarke, Victoria},
	date = {2006},
}

@article{jones_measuring_2019,
	title = {Measuring conceptual understanding in randomised controlled trials: Can comparative judgement help?},
	volume = {45},
	url = {https://doi.org/10.1002/berj.3519},
	doi = {10.1002/berj.3519},
	abstract = {An impediment to conducting high-quality quantitative research studies in education is the paucity of valid measures of learning gains. Studies often seek to investigate students’ deep, conceptual understanding yet many measures assess only surface, procedural understanding. One reason is that the development of validated measures of conceptual understanding is resource intensive and time consuming, and success is not guaranteed. We evaluated a novel and efficient technique, based on comparative judgement, for assessing conceptual understanding. We applied the technique to a randomised controlled trial in which students were taught simple algebra based on either the Grid Algebra or the {MiGen} software package. The participants were Year 5 students (N = 188) drawn from four primary schools who had not encountered algebra previously. An instrument from the literature (Concepts in Secondary Mathematics and Science: Algebra Scale) and a novel comparative judgement assessment were administered following the intervention. Students in the Grid Algebra condition outperformed those in the {MiGen} condition on both post-test measures. The comparative judgement technique performed similarly to the standard instrument but was far more efficient to design and implement. The technique can, in principle, be quickly applied to any target concept of interest. We conclude that comparative judgement is a valid, reliable and practical tool that could help to increase both the quantity and quality of quantitative research in education.},
	pages = {662--680},
	number = {3},
	journaltitle = {British Educational Research Journal},
	author = {Jones, Ian and Bisson, Marie and Gilmore, Camilla and Inglis, Matthew},
	date = {2019},
	keywords = {assessment, comparative judgement, mathematics education, quantitative research methods},
}

@article{jones_peer_2015,
	title = {Peer assessment using comparative and absolute judgement},
	volume = {47},
	doi = {10.1016/j.stueduc.2015.09.004},
	pages = {93--101},
	journaltitle = {Studies in Educational Evaluation},
	author = {Jones, Ian and Wheadon, Chris},
	date = {2015},
}

@inproceedings{hunter_free-response_2018,
	location = {Auckland, New Zealand},
	title = {Free-response tasks in primary mathematics: a window on students’ thinking},
	volume = {41},
	url = {https://eric.ed.gov/?id=ED592426},
	eventtitle = {{MERGA} 2018},
	pages = {400--407},
	booktitle = {Proceedings of the 41st annual conference of the Mathematics Education Research Group of Australasia},
	publisher = {The Mathematics Education Research Group of Australasia Inc.},
	author = {Hunter, Jodie and Jones, Ian},
	editor = {Hunter, Jodie and Darragh, Lisa and Perger, Pam},
	date = {2018},
}

@article{kimbell_evolving_2012,
	title = {Evolving project e-scape for national assessment},
	volume = {22},
	issn = {0957-7572},
	url = {http://www.springerlink.com/content/e878u5h84711g073/abstract/},
	doi = {10.1007/s10798-011-9190-4},
	abstract = {In the opening paper in this Special Edition I outlined the major issues that led to the establishment of project e-scape . The project was intended to develop systems and approaches that enabled learners to build real-time web-based portfolios of their performance (initially) in design \& technology and additionally to build systems and approaches to facilitate the web-based assessment of those portfolios. The project was commissioned by the Qualifications and Curriculum Authority ({QCA}) with additional ‘buy-in’ from Awarding Bodies—who were seen by {QCA} as the leading beneficiaries of a successful project. The project was designed in three phases. I have outlined—in the Introduction to this Special Edition—the early exploratory work that we undertook within phase 1, the aim of which was to prove the viability of the concept. This was achieved, and {QCA} then commissioned phase 2 with a brief to build a working prototype system and run it through a national pilot-testing programme in 2006. Age 15 was the target age-group, aligning as closely as we could with the Awarding Body requirements for the General Certificate of Secondary Education ({GCSE}) that runs with age 16 learners. The successes of the phase 2 prototype—both as classroom activity and as reliable assessment—led {QCA} and Becta (the body responsible for funding {ICT} developments in schools) to commission phase 3 in which we explored the potential of the e-scape system for wider application. Specifically, we were required to demonstrate the transferability of the system to other curriculum areas beyond design \& technology, and the scalability of the system if it were to be used for national assessment purposes, with hundreds of thousands of candidates. In this paper, I outline the approach that we adopted through the e-scape research; describe the major elements of the work both in terms of classroom/curriculum practice and in terms of new approaches to assessment; and analyse some of the key issues that arise from it.},
	pages = {135--155},
	number = {2},
	journaltitle = {International Journal of Technology and Design Education},
	author = {Kimbell, Richard},
	urldate = {2012-08-06},
	date = {2012},
	keywords = {Humanities, Social Sciences and Law},
	file = {SpringerLink Snapshot:/Users/maij/Zotero/storage/JS9QZXPJ/abstract.html:text/html},
}

@article{thurstone_method_1927,
	title = {The method of paired comparisons for social values},
	volume = {21},
	issn = {0096-851X},
	abstract = {{\textless}p{\textgreater}{\textless}br/{\textgreater}This is an attempt to apply the ideas of psychophysical measurement in the field of social values. Some of the psychophysical methods have been applied in a crude way to the measurement of educational products such as handwriting and English composition, and it seems feasible to apply the same ideas as well to social values although the attempt cannot readily be made without making compromises that the psychophysicist would not tolerate. The application of the principles of psychophysical measurement to educational products has been made with more or less similar logical handicaps but these do not seem to have disturbed the popularity of these methods in the field of educational measurement. Since the final results show a rather satisfactory internal consistency, one may possibly assume that the methods, the theoretically imperfect, have some value also in social psychology. For the present experiment the seriousness of different crimes or offenses was chosen for such measurement. The seriousness of an offense we shall assume to be the seriousness as judged rather than as measured in terms of objective consequences or in some normative way. Nineteen offenses were judged: abortion, adultery, arson, assault and battery, bootlegging, burglary, counterfeiting, embezzlement, forgery, homicide, kidnapping, larceny, libel, perjury, rape, receiving stolen goods, seduction, smuggling, and vagrancy. The offenses were arranged in pairs so that every one of them was paired with every other one. The total number of pairs of offenses presented was therefore n(n-1)/2 = 171. College student subjects were presented with the paired offenses and asked to choose which they considered to be the more serious crime. Results show that qualitative judgments of a rather intangible sort, loaded usually with personal opinion, bias, and even strong feeling, and regarded generally as the direct antithesis of quantitative measurement, are nevertheless amenable to the type of quantitative analysis which is associated historically with psychophysics. It is of some interest to see that a set of numerical values can be established by which the 171 observed proportions of judgments about crimes and offenses can be summarized in generalized form. ({PsycINFO} Database Record (c) 2006 {APA}, all rights reserved){\textless}/p{\textgreater}},
	pages = {384--400},
	journaltitle = {Journal of Abnormal and Social Psychology},
	author = {Thurstone, L.L.},
	urldate = {2011-06-15},
	date = {1927},
	keywords = {crime, paired comparison},
	file = {ScienceDirect Snapshot:/Users/maij/Zotero/storage/4ZAR7RWH/S0096851X07600681.html:text/html},
}

@inproceedings{bell_standards_1997,
	location = {York},
	title = {Standards in a-level mathematics, 1986 to 1995},
	eventtitle = {British Educational Research Association Annual Conference},
	author = {Bell, John and Bramley, Tom and Raikes, Nicholas},
	date = {1997},
	keywords = {assessment, escape},
}

@book{piaget_childs_1952,
	location = {London},
	title = {The Child's Conception of Number},
	publisher = {Routledge \& Kegan Paul Ltd},
	author = {Piaget, J.},
	date = {1952},
	keywords = {=},
}

@article{heldsinger_using_2010,
	title = {Using the method of pairwise comparison to obtain reliable teacher assessments},
	volume = {37},
	issn = {0311-6999},
	url = {10.1007/BF03216919},
	doi = {10.1007/BF03216919},
	pages = {1--19},
	journaltitle = {The Australian Educational Researcher},
	shortjournal = {Aust. Educ. Res.},
	author = {Heldsinger, Sandra and Humphry, Stephen},
	urldate = {2011-08-08},
	date = {2010-08},
	file = {SpringerLink - The Australian Educational Researcher, Volume 37, Number 2:/Users/maij/Zotero/storage/TF9M6W7P/6qj512x783736520.html:text/html},
}

@article{black_high-stakes_2012,
	title = {High-stakes examinations to support policy},
	volume = {2},
	pages = {1--31},
	number = {5},
	journaltitle = {Educational Designer},
	author = {Black, Paul and Burkhardt, Hugh and Daro, Phil and Jones, Ian and Lappan, Glenda and Pead, Daniel and Stephens, Max},
	date = {2012},
}

@article{crooks_defining_2014,
	title = {Defining and measuring conceptual knowledge in mathematics},
	volume = {34},
	issn = {0273-2297},
	url = {http://www.sciencedirect.com/science/article/pii/S0273229714000380},
	doi = {10.1016/j.dr.2014.10.001},
	abstract = {A long tradition of research on mathematical thinking has focused on procedural knowledge, or knowledge of how to solve problems and enact procedures. In recent years, however, there has been a shift toward focusing, not only on solving problems, but also on conceptual knowledge. In the current work, we reviewed (1) how conceptual knowledge is defined in the mathematical thinking literature, and (2) how conceptual knowledge is defined, operationalized, and measured in three mathematical domains: equivalence, cardinality, and inversion. We uncovered three general issues. First, few investigators provide explicit definitions of conceptual knowledge. Second, the definitions that are provided are often vague or poorly operationalized. Finally, the tasks used to measure conceptual knowledge do not always align with theoretical claims about mathematical understanding. Together, these three issues make it challenging to understand the development of conceptual knowledge, its relationship to procedural knowledge, and how it can best be taught to students. In light of these issues, we propose a general framework that divides conceptual knowledge into two facets: knowledge of general principles and knowledge of the principles underlying procedures.},
	pages = {344--377},
	number = {4},
	journaltitle = {Developmental Review},
	shortjournal = {Developmental Review},
	author = {Crooks, Noelle M. and Alibali, Martha W.},
	urldate = {2015-01-15},
	date = {2014-12},
	keywords = {conceptual knowledge, Cardinality, Equivalence, Inversion, Mathematical thinking},
	file = {ScienceDirect Snapshot:/Users/maij/Zotero/storage/V53UMKP7/S0273229714000380.html:text/html},
}

@book{newton_validity_2014,
	title = {Validity in Educational and Psychological Assessment},
	isbn = {978-1-4739-0406-4},
	abstract = {Lecturers, request your electronic inspection copy to review it for your course.   Validity is the hallmark of quality for educational and psychological measurement. But what does quality mean in this context? And to what, exactly, does the concept of validity apply? These apparently innocuous questions parachute the unwary inquirer into a minefield of tricky ideas. This book guides you through this minefield, investigating how the concept of validity has evolved from the nineteenth century to the present day. Communicating complicated concepts straightforwardly, the authors answer questions like:   What does 'validity' mean? What does it mean to 'validate'? How many different kinds of validity are there? When does validation begin and end? Is reliability a part of validity, or distinct from it?  This book will be of interest to anyone with a professional or academic interest in evaluating the quality of educational or psychological assessments, measurements and diagnoses.},
	pagetotal = {281},
	publisher = {{SAGE}},
	author = {Newton, Paul and Shaw, Stuart},
	date = {2014-04-15},
	langid = {english},
	keywords = {Education / Testing \& Measurement, Education / Evaluation \& Assessment},
}

@article{evans_mathematicians_2022,
	title = {Do mathematicians and undergraduates agree about explanation quality?},
	volume = {111},
	url = {https://doi.org/10.1007/s10649-022-10164-2},
	doi = {10.1007/s10649-022-10164-2},
	pages = {445--467},
	number = {3},
	journaltitle = {Educational Studies in Mathematics},
	author = {Evans, Tanya and Mejía-Ramos, Juan Pablo and Inglis, Matthew},
	date = {2022},
	note = {Publisher: Springer},
}

@article{keppens_measuring_2019,
	title = {Measuring pre-service teachers' professional vision of inclusive classrooms: A video-based comparative judgement instrument},
	volume = {78},
	url = {https://doi.org/10.1016/j.tate.2018.10.007},
	doi = {10.1016/j.tate.2018.10.007},
	pages = {1--14},
	journaltitle = {Teaching and Teacher Education},
	author = {Keppens, Karolien and Consuegra, Els and Goossens, Maarten and De Maeyer, Sven and Vanderlinde, Ruben},
	date = {2019},
	note = {Publisher: Elsevier},
}

@article{thurstone_law_1927,
	title = {A law of comparative judgment},
	volume = {34},
	issn = {0033-295X},
	url = {https://doi.org/10.1037/h0070288},
	doi = {10.1037/h0070288},
	pages = {273--286},
	journaltitle = {Psychological Review},
	author = {Thurstone, L. L.},
	urldate = {2010-01-08},
	date = {1927},
	keywords = {assessment, escape},
	file = {PsycNET - Display Record:/Users/maij/Zotero/storage/KTT3RYKR/273.html:text/html},
}

@article{bisson_teaching_2019,
	title = {Teaching using contextualised and decontextualised representations: examining the case of differential calculus through a comparative judgement technique},
	volume = {22},
	url = {https://doi.org/10.1080/14794802.2019.1692060},
	doi = {10.1080/14794802.2019.1692060},
	pages = {284--303},
	number = {3},
	journaltitle = {Research in Mathematics Education},
	author = {Bisson, Marie-Josée and Gilmore, Camilla and Inglis, Matthew and Jones, Ian},
	date = {2019},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14794802.2019.1692060},
}

@inproceedings{gijsen_complexity_2021,
	title = {The complexity of comparative judgments in assessing argumentative writing: an eye tracking study},
	url = {https://doi.org/10.3389/feduc.2020.582800},
	pages = {314},
	booktitle = {Frontiers in Education},
	publisher = {Frontiers},
	author = {Gijsen, Marijn and Van Daal, Tine and Lesterhuis, Marije and Gijbels, David and De Maeyer, Sven},
	date = {2021},
}

@article{bramley_effect_2018,
	title = {The effect of adaptivity on the reliability coefficient in Adaptive Comparative Judgement},
	volume = {26},
	issn = {0969-594X, 1465-329X},
	url = {https://doi.org/10.1080/0969594X.2017.1418734},
	doi = {10.1080/0969594X.2017.1418734},
	pages = {43--58},
	number = {1},
	journaltitle = {Assessment in Education: Principles, Policy \& Practice},
	author = {Bramley, Tom and Vitello, Sylvia},
	urldate = {2018-09-14},
	date = {2018},
	langid = {english},
}

@article{hunter_mm_2004,
	title = {{MM} algorithms for generalized Bradley-Terry models},
	volume = {32},
	url = {https://doi.org/10.1214/aos/1079120141},
	doi = {10.1214/aos/1079120141},
	pages = {384--406},
	number = {1},
	journaltitle = {The Annals of Statistics},
	author = {Hunter, David R},
	date = {2004},
	note = {Publisher: Institute of Mathematical Statistics},
}

@article{sa_mathematicians_2024,
	title = {Do mathematicians agree about mathematical beauty?},
	volume = {15},
	url = {https://doi.org/10.1007/s13164-022-00669-3},
	doi = {10.1007/s13164-022-00669-3},
	pages = {299--325},
	journaltitle = {Review of Philosophy and Psychology},
	author = {Sa, Rentuya and Alcock, Lara and Inglis, Matthew and Tanswell, Fenner Stanley},
	date = {2024},
	note = {Publisher: Springer},
}

@article{kelly_critiquing_2022,
	title = {Critiquing the rationales for using comparative judgement: a call for clarity},
	volume = {29},
	url = {https://doi.org/10.1080/0969594X.2022.2147901},
	doi = {10.1080/0969594X.2022.2147901},
	pages = {674--688},
	number = {6},
	journaltitle = {Assessment in Education: Principles, Policy \& Practice},
	author = {Kelly, Kate Tremain and Richardson, Mary and Isaacs, Talia},
	date = {2022},
	note = {Publisher: Taylor \& Francis},
}

@article{bartholomew_tool_2019,
	title = {A tool for formative assessment and learning in a graphics design course: Adaptive Comparative Judgement},
	volume = {22},
	url = {https://lens.org/007-840-977-956-003},
	doi = {10.1080/14606925.2018.1560876},
	pages = {73--95},
	number = {1},
	journaltitle = {The Design Journal},
	author = {Bartholomew, Scott R. and Zhang, Liwei and Bravo, Esteban Garcia and Strimel, Greg J.},
	date = {2019-01-02},
}

@article{stadthagen-gonzalez_using_2017,
	title = {Using two-alternative forced choice tasks and Thurstone’s law of comparative judgments for code-switching research},
	volume = {8},
	url = {https://doi.org/10.1177/1367006917728390},
	doi = {10.1177/1367006917728390},
	pages = {67--97},
	number = {1},
	journaltitle = {Linguistic Approaches to Bilingualism},
	author = {Stadthagen-Gonzalez, Hans and López, Luis and Couto, M. Carmen Parafita and Parraga, C. Alejandro},
	date = {2017-09-18},
}

@article{bisson_learning_2023,
	title = {Learning words with unfamiliar orthography: The role of cognitive abilities},
	volume = {45},
	url = {https://doi.org/10.1017/S0272263122000390},
	doi = {10.1017/S0272263122000390},
	pages = {838--852},
	number = {4},
	journaltitle = {Studies in Second Language Acquisition},
	author = {Bisson, Marie-Josée},
	date = {2023},
	note = {Publisher: Cambridge University Press},
}

@article{woollacott_spatial_2023,
	title = {The spatial contiguity principle in mathematics textbooks},
	url = {https://doi.org/10.1080/14794802.2022.2158122},
	doi = {10.1080/14794802.2022.2158122},
	pages = {1--21},
	journaltitle = {Research in Mathematics Education},
	author = {Woollacott, Bethany and Alcock, Lara and Inglis, Matthew},
	date = {2023},
	note = {Publisher: Taylor \& Francis},
}

@article{kimbell_examining_2021,
	title = {Examining the reliability of Adaptive Comparative Judgement ({ACJ}) as an assessment tool in educational settings},
	url = {https://doi.org/10.1007/s10798-021-09654-w},
	doi = {10.1007/s10798-021-09654-w},
	pages = {1--15},
	journaltitle = {International Journal of Technology and Design Education},
	author = {Kimbell, Richard},
	date = {2021-02-23},
}

@article{cattelan_dynamic_2013,
	title = {Dynamic Bradley–Terry modelling of sports tournaments},
	volume = {62},
	url = {https://lens.org/027-150-047-044-961},
	doi = {10.1111/j.1467-9876.2012.01046.x},
	pages = {135--150},
	number = {1},
	journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Cattelan, Manuela and Varin, Cristiano and Firth, David},
	date = {2013},
}

@article{attali_ranking_2014,
	title = {A Ranking Method for Evaluating Constructed Responses},
	volume = {74},
	url = {https://lens.org/091-132-647-349-699},
	doi = {10.1177/0013164414527450},
	pages = {795--808},
	number = {5},
	journaltitle = {Educational and Psychological Measurement},
	author = {Attali, Yigal},
	date = {2014-04-02},
}

@article{bartholomew_comparison_2018,
	title = {A comparison of traditional and adaptive comparative judgment assessment techniques for freshmen engineering design projects},
	volume = {34},
	url = {https://lens.org/163-938-197-264-411},
	pages = {20--33},
	number = {1},
	journaltitle = {International Journal of Engineering Education},
	author = {Bartholomew, Scott R. and Strimel, Greg J. and Jackson, W. Andrew},
	date = {2018},
}

@article{crompvoets_bias_2021,
	title = {On the bias and stability of the results of comparative judgment},
	volume = {6},
	url = {https://doi.org/10.31234/osf.io/kq4jh},
	doi = {10.31234/osf.io/kq4jh},
	abstract = {Comparative judgment is a method that allows measurement of a competence by comparison of items with other items. In educational measurement, where comparative judgment is becoming an increasingly popular assessment method, items are mostly students' responses to an assignment or an examination. For assessments using comparative judgment, the Scale Separation Reliability ({SSR}) is used to estimate the reliability of the measurement. Previous research has shown that the {SSR} may overestimate reliability when the pairs to be compared are selected with certain adaptive algorithms, when raters use different underlying models/truths, or when the true variance of the item parameters is below one. This research investigated bias and stability of the components of the {SSR} in relation to the number of comparisons per item to increase understanding of the {SSR}. We showed that many comparisons are required to obtain an accurate estimate of the item variance, but that the {SSR} can be useful even when the variance of the items is overestimated. Lastly, we recommend adjusting the general guideline for the required number of comparisons per item to 41 comparisons per item. This recommendation partly depends on the number of items and the true variance in our simulation study and needs further investigation.},
	pages = {788202},
	author = {Crompvoets, Elise Anne Victoire and Béguin, Anton and Sijtsma, Klaas},
	date = {2021-10},
	keywords = {bias, comparative judgment, pairwise comparison, reliability, Social and Behavioral Sciences, stability},
}

@thesis{sa_what_2023,
	location = {Loughborough},
	title = {What is Mathematical Beauty? An Experimental Philosophical Investigation into Mathematicians’ Aesthetic Judgements},
	institution = {Loughborough University},
	type = {phdthesis},
	author = {Sa, Rentuya},
	date = {2023},
}

@article{foulkes_effects_2023,
	title = {The Effects of Concreteness on Mathematical Manipulative Choice},
	volume = {17},
	url = {https://doi.org/10.1111/mbe.12374},
	doi = {10.1111/mbe.12374},
	pages = {185--196},
	number = {3},
	journaltitle = {Mind, Brain, and Education},
	author = {Foulkes, Megan and Sella, Francesco and Wege, Theresa Elise and Gilmore, Camilla},
	date = {2023},
	note = {Publisher: Wiley Online Library},
}

@article{clayton_inhibition_2015,
	title = {Inhibition in dot comparison tasks},
	volume = {47},
	url = {https://doi.org/10.1007/s11858-014-0655-2},
	doi = {10.1007/s11858-014-0655-2},
	pages = {759--770},
	number = {5},
	journaltitle = {{ZDM}–Mathematics Education},
	author = {Clayton, Sarah and Gilmore, Camilla},
	date = {2015},
	note = {Publisher: Springer},
}

@article{seymour_bayesian_2022,
	title = {The Bayesian Spatial Bradley–Terry Model: Urban Deprivation Modelling in Tanzania},
	volume = {71},
	issn = {0035-9254},
	url = {https://doi.org/10.1111/rssc.12532},
	doi = {10.1111/rssc.12532},
	shorttitle = {The Bayesian Spatial Bradley–Terry Model},
	abstract = {Identifying the most deprived regions of any country or city is key if policy makers are to design successful interventions. However, locating areas with the greatest need is often surprisingly challenging in developing countries. Due to the logistical challenges of traditional household surveying, official statistics can be slow to be updated; estimates that exist can be coarse, a consequence of prohibitive costs and poor infrastructures; and mass urbanization can render manually surveyed figures rapidly out-of-date. Comparative judgement models, such as the Bradley–Terry model, offer a promising solution. Leveraging local knowledge, elicited via comparisons of different areas' affluence, such models can both simplify logistics and circumvent biases inherent to household surveys. Yet widespread adoption remains limited, due to the large amount of data existing approaches still require. We address this via development of a novel Bayesian Spatial Bradley–Terry model, which substantially decreases the number of comparisons required for effective inference. This model integrates a network representation of the city or country, along with assumptions of spatial smoothness that allow deprivation in one area to be informed by neighbouring areas. We demonstrate the practical effectiveness of this method, through a novel comparative judgement data set collected in Dar es Salaam, Tanzania.},
	pages = {288--308},
	number = {2},
	journaltitle = {Journal of the Royal Statistical Society Series C: Applied Statistics},
	author = {Seymour, Rowland G. and Sirl, David and Preston, Simon P. and Dryden, Ian L. and Ellis, Madeleine J. A. and Perrat, Bertrand and Goulding, James},
	urldate = {2024-05-30},
	date = {2022-03},
}

@article{verhavert_meta-analysis_2019,
	title = {A meta-analysis on the reliability of comparative judgement},
	volume = {26},
	issn = {0969-594X},
	url = {https://doi.org/10.1080/0969594X.2019.1602027},
	doi = {10.1080/0969594X.2019.1602027},
	abstract = {Comparative Judgement ({CJ}) aims to improve the quality of performance-based assessments by letting multiple assessors judge pairs of performances. {CJ} is generally associated with high levels of reliability, but there is also a large variation in reliability between assessments. This study investigates which assessment characteristics influence the level of reliability. A meta-analysis was performed on the results of 49 {CJ} assessments. Results show that there was an effect of the number of comparisons on the level of reliability. In addition, the probability of reaching an asymptote in the reliability, i.e., the point where large effort is needed to only slightly increase the reliability, was larger for experts and peers than for novices. For reliability levels of.70 between 10 and 14 comparisons per performance are needed. This rises to 26 to 37 comparisons for a reliability of.90.},
	pages = {541--562},
	number = {5},
	journaltitle = {Assessment in Education: Principles, Policy \& Practice},
	author = {Verhavert, San and Bouwer, Renske and Donche, Vincent and De Maeyer, Sven},
	date = {2019-09},
	note = {Publisher: Routledge},
	keywords = {meta-analysis, Comparative Judgement ({CJ}), performance-based assessment, Scale Separation Reliability ({SSR}), task-complexity},
}

@article{zucco_measuring_2019,
	title = {Measuring Portfolio Salience Using the Bradley–Terry Model: An Illustration with Data from Brazil},
	volume = {6},
	issn = {2053-1680},
	doi = {10.1177/2053168019832089},
	shorttitle = {Measuring Portfolio Salience Using the Bradley–Terry Model},
	abstract = {How do political actors value different portfolios? We propose a new approach to measuring portfolio salience by analysing paired comparisons using the Bradley–Terry model. Paired-comparison data are easy to collect using surveys that are user-friendly, rapid, and inexpensive. We implement the approach with serving legislators in Brazil, a particularly difficult case to assess portfolio salience due to the large number of cabinet positions. Our estimates of portfolio values are robust to variations in implementation of the method. Legislators and academics have broadly similar views of the relative worth of cabinet posts. Respondent valuations of portfolios deviate considerably from what would be predicted by objective measures such as budget, policy influence, and opportunities for patronage. Substantively, we show that portfolio salience varies greatly and affects the calculation of formateur advantage and coalescence/proportionality rule measures.},
	pages = {2053168019832089},
	number = {1},
	journaltitle = {Research \& Politics},
	author = {Zucco, Cesar and Batista, Mariana and Power, Timothy J.},
	urldate = {2024-05-24},
	date = {2019-01},
	note = {Publisher: {SAGE} Publications Ltd},
}

@article{routh_rating_2023,
	title = {Rating and ranking preparedness characteristics important for veterinary workplace clinical training: a novel application of pairwise comparisons and the Elo algorithm},
	volume = {10},
	doi = {10.3389/fmed.2023.1128058},
	pages = {1128058},
	journaltitle = {Frontiers in Medicine},
	author = {Routh, Jennifer and Paramasivam, Sharmini Julita and Cockcroft, Peter and Wood, Sarah and Remnant, John and Westermann, Cornélie and Reid, Alison and Pawson, Patricia and Warman, Sheena and Nadarajah, Vishna Devi and {others}},
	date = {2023},
	note = {Publisher: Frontiers},
}

@inproceedings{jones_measuring_2013,
	location = {Kiel, Germany},
	title = {Measuring conceptual understanding: The case of fractions},
	volume = {3},
	pages = {113--120},
	booktitle = {Proceedings of the 37th Conference of the International Group for the Psychology of Mathematics Education},
	publisher = {{IGPME}},
	author = {Jones, Ian and Inglis, Matthew and Gilmore, Camilla and Hodgen, Jeremy},
	editor = {Lindmeier, A. M. and Heinze, A},
	date = {2013},
}

@article{davies_assessing_2022,
	title = {Assessing proof reading comprehension using summaries},
	volume = {8},
	url = {https://doi.org/10.1007/s40753-021-00157-6},
	doi = {10.1007/s40753-021-00157-6},
	pages = {469--489},
	journaltitle = {International Journal of Research in Undergraduate Mathematics Education},
	author = {Davies, Ben and Jones, Ian},
	date = {2022},
}

@article{wheadon_comparative_2020,
	title = {A comparative judgement approach to the large-scale assessment of primary writing in England},
	volume = {27},
	url = {https://doi.org/10.1080/0969594X.2019.1700212},
	doi = {10.1080/0969594X.2019.1700212},
	pages = {46--64},
	number = {1},
	journaltitle = {Assessment in Education: Principles, Policy \& Practice},
	author = {Wheadon, Christopher and Barmby, Patrick and Christodoulou, Daisy and Henderson, Brian},
	date = {2020},
}

@article{kinnear_comparative_2025,
	title = {Comparative judgement as a research tool: a meta-analysis of application and reliability},
	volume = {57},
	url = {https://doi.org/10.3758/s13428-025-02744-w},
	doi = {10.3758/s13428-025-02744-w},
	pages = {222},
	journaltitle = {Behavior Research Methods},
	author = {Kinnear, George and Jones, Ian and Davies, Ben},
	date = {2025},
}

@article{islam_bradley-terry_2022,
	title = {Bradley-Terry model for assessing the performance of ten odi cricket teams adjusting for home ground effect},
	volume = {15},
	url = {https://doi.org/10.6339/JDS.201710_15(4).00005},
	doi = {10.6339/JDS.201710_15(4).00005},
	pages = {657--668},
	number = {4},
	journaltitle = {Journal of Data Science},
	author = {Islam, Md Mazharul and Khan, Jahidur Rahman and Raheem, Enayetur},
	date = {2022},
	note = {Publisher: School of Statistics, Renmin University of China},
}

@article{sangwin_investigating_2024,
	title = {Investigating insight and rigour as separate constructs in mathematical proof},
	url = {https://doi.org/10.1080/14794802.2024.2379301},
	doi = {10.1080/14794802.2024.2379301},
	pages = {1--29},
	journaltitle = {Research in Mathematics Education},
	author = {Sangwin, {CJ} and Kinnear, George},
	date = {2024},
	note = {Publisher: Taylor \& Francis},
}

@article{roose_measuring_2019,
	title = {Measuring teachers’ professional vision of inclusive classrooms through video-based comparative judgement. What does it mean to misfit?},
	volume = {98},
	url = {https://doi.org/10.1016/j.ijer.2019.09.004},
	doi = {10.1016/j.ijer.2019.09.004},
	pages = {257--271},
	journaltitle = {International journal of educational research},
	author = {Roose, Iris and Vantieghem, Wendelien and Van Damme, Kristof and Lambert, Peter and Vanderlinde, Ruben and Van Avermaet, Piet},
	date = {2019},
	note = {Publisher: Elsevier},
}

@article{reips_web-based_2021,
	title = {Web-based research in psychology},
	volume = {229},
	url = {https://doi.org/10.1027/2151-2604/a000475},
	doi = {10.1027/2151-2604/a000475},
	pages = {198--213},
	number = {4},
	journaltitle = {Zeitschrift für Psychologie},
	author = {Reips, Ulf-Dietrich},
	date = {2021},
	note = {Publisher: Hogrefe Publishing},
}

@article{van_etten_crop_2019,
	title = {Crop variety management for climate adaptation supported by citizen science},
	volume = {116},
	url = {https://doi.org/10.1073/pnas.181372011},
	doi = {10.1073/pnas.181372011},
	pages = {4194--4199},
	number = {10},
	journaltitle = {Proceedings of the National Academy of Sciences},
	author = {van Etten, Jacob and de Sousa, Kauê and Aguilar, Amílcar and Barrios, Mirna and Coto, Allan and Dell’Acqua, Matteo and Fadda, Carlo and Gebrehawaryat, Yosef and van de Gevel, Jeske and Gupta, Arnab and {others}},
	date = {2019},
	note = {Publisher: National Acad Sciences},
}

@inproceedings{jones_validity_2024,
	location = {Utrecht (The Netherlands)},
	title = {Validity objections to comparative judgement},
	url = {https://doi.org/10.5281/zenodo.14231455},
	doi = {10.5281/zenodo.14231455},
	eventtitle = {Feedback \& Assessment in Mathematics Education ({FAME})},
	pages = {142--149},
	booktitle = {Proceedings of {FAME} 1 – Feedback \& Assessment in Mathematics Education ({ETC} 14)},
	publisher = {Utrecht University and {ERME}},
	author = {Jones, Ian},
	editor = {Iannone, Paola and Moons, Filip and Drüke-Noe, Christina and Geraniou, Eirini and Morselli, Francesca and Klingbeil, Katrin and Veldhuis, Michiel and Olsher, Shai and Corinna, Hankeln and Gonscherowski, Peter},
	date = {2024-06-05},
}

@article{torkildsen_norwegian_2025,
	title = {Norwegian mathematics teacher educators’ and research mathematicians’ views on different aspects of mathematical definitions: a comparative judgement study},
	url = {https://doi.org/10.1007/s10763-024-10534-7},
	doi = {10.1007/s10763-024-10534-7},
	pages = {1--24},
	journaltitle = {International Journal of Science and Mathematics Education},
	author = {Torkildsen, Hermund André and Forbregd, Tore A and Reid, David A and Kanwal, Shaista},
	date = {2025},
	note = {Publisher: Springer},
}

@inproceedings{adigwe_can_2025,
	title = {Can We" Cherry-Pick"? Investigating Multiple Renditions from a Generative Speech Synthesis Model},
	url = {https://doi.org/10.1109/ICASSP49660.2025.10890697},
	doi = {10.1109/ICASSP49660.2025.10890697},
	pages = {1--5},
	booktitle = {{ICASSP} 2025-2025 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	publisher = {{IEEE}},
	author = {Adigwe, Adaeze and Wallbridge, Sarenne and Tu, Zehai and Lai, Catherine and King, Simon},
	date = {2025},
}

@article{tanswell_comparative_2023,
	title = {Comparative judgement for experimental philosophy: A method for assessing ordinary meaning in vehicles in the park cases},
	volume = {38},
	url = {https://doi.org/10.1080/09515089.2023.2263036},
	doi = {10.1080/09515089.2023.2263036},
	pages = {1558--1578},
	number = {4},
	journaltitle = {Philosophical Psychology},
	author = {Tanswell, Fenner and Davies, Ben and Jones, Ian and Kinnear, George},
	date = {2023},
	note = {Publisher: Taylor \& Francis},
}

@article{chambers_exploring_2022,
	title = {Exploring the validity of comparative judgement: Do judges attend to construct-irrelevant features?},
	volume = {7},
	url = {https://doi.org/10.3389/feduc.2022.802392},
	doi = {10.3389/feduc.2022.802392},
	pages = {802392},
	journaltitle = {Frontiers in Education},
	author = {Chambers, Lucy and Cunningham, Euan},
	date = {2022},
}

@article{sun_rethinking_2025,
	title = {Rethinking Bradley-Terry Models in Preference-Based Reward Modeling: Foundations, Theory, and Alternatives},
	url = {https://doi.org/10.48550/arXiv.2411.04991},
	doi = {https://doi.org/10.48550/arXiv.2411.04991},
	abstract = {The Bradley-Terry ({BT}) model is a common and successful practice in reward modeling for Large Language Model ({LLM}) alignment. However, it remains unclear why this model -- originally developed for multi-player stochastic game matching -- can be adopted to convert pairwise response comparisons to reward values and make predictions. Especially given the fact that only a limited number of prompt-response pairs are sparsely compared with others. In this paper, we first revisit the foundations of using {BT} models in reward modeling, and establish the convergence rate of {BT} reward models based on deep neural networks using embeddings, providing a theoretical foundation for their use. Despite theoretically sound, we argue that the {BT} model is not a necessary choice from the perspective of downstream optimization. This is because a reward model only needs to preserve the correct ranking predictions through a monotonic transformation of the true reward. We highlight the critical concept of order consistency in reward modeling and demonstrate that the {BT} model possesses this property. Consequently, we propose a simple and straightforward upper-bound algorithm, compatible with off-the-shelf binary classifiers, as an alternative order-consistent reward modeling objective. To offer practical insights, we empirically evaluate the performance of these different reward modeling approaches across more than 12,000 experimental setups, using 6 base {LLMs}, 2 datasets, and diverse annotation designs that vary in quantity, quality, and pairing choices in preference annotations.},
	journaltitle = {arxiv},
	author = {Sun, Hao and Shen, Yunyi and Ton, Jean-Francois},
	date = {2025},
	note = {\_eprint: 2411.04991},
}

@article{davenport_imagining_2022,
	title = {Imagining the Sun: using comparative judgement to assess the impact of cross-curricular solar physics workshops},
	volume = {21},
	url = {https://doi.org/10.22323/2.21060206},
	doi = {10.22323/2.21060206},
	pages = {A06},
	number = {6},
	journaltitle = {Journal of Science Communication},
	author = {Davenport, Carol and Morton, Richard},
	date = {2022},
	note = {Publisher: {SISSA} Medialab srl},
}

@article{han_comparative_2022,
	title = {A comparative judgment approach to assessing Chinese Sign Language interpreting},
	volume = {39},
	url = {https://doi.org/10.1177/02655322211038977},
	doi = {10.1177/02655322211038977},
	abstract = {The quality of sign language interpreting ({SLI}) is a gripping construct among practitioners, educators and researchers, calling for reliable and valid assessment. There has been a diverse array of methods in the extant literature to measure {SLI} quality, ranging from traditional error analysis to recent rubric scoring. In this study, we want to expand the terrain of {SLI} assessment, by exploring and evaluating a novel method, known as comparative judgment ({CJ}), to assess {SLI} quality. Briefly, {CJ} involves judges to compare two like objects/items and make a decision by choosing the one with higher quality. The binary outcomes from repeated comparisons by a group of judges are then modelled statistically to produce standardized estimates of perceived quality for each object/item. We recruited 12 expert judges to operationalize {CJ} via a computerized system to assess the quality of Chinese Sign Language interpreting produced by 36 trainee interpreters. Overall, our analysis of quantitative and qualitative data provided preliminary evidential support for the validity and utility of {CJ} in {SLI} assessment. We discussed these results in relation to previous {SLI} literature, and suggested future research to cast light on {CJ}’s usefulness in applied assessment contexts.},
	pages = {289--312},
	number = {2},
	journaltitle = {Language Testing},
	author = {Han, Chao and Xiao, Xiaoyan},
	date = {2022},
	note = {\_eprint: https://doi.org/10.1177/02655322211038977},
}

@article{hollis_scoring_2018,
	title = {Scoring best-worst data in unbalanced many-item designs, with applications to crowdsourcing semantic judgments},
	volume = {50},
	issn = {1554-3528},
	url = {https://doi.org/10.3758/s13428-017-0898-2},
	doi = {10.3758/s13428-017-0898-2},
	abstract = {Best-worst scaling is a judgment format in which participants are presented with a set of items and have to choose the superior and inferior items in the set. Best-worst scaling generates a large quantity of information per judgment because each judgment allows for inferences about the rank value of all unjudged items. This property of best-worst scaling makes it a promising judgment format for research in psychology and natural language processing concerned with estimating the semantic properties of tens of thousands of words. A variety of different scoring algorithms have been devised in the previous literature on best-worst scaling. However, due to problems of computational efficiency, these scoring algorithms cannot be applied efficiently to cases in which thousands of items need to be scored. New algorithms are presented here for converting responses from best-worst scaling into item scores for thousands of items (many-item scoring problems). These scoring algorithms are validated through simulation and empirical experiments, and considerations related to noise, the underlying distribution of true values, and trial design are identified that can affect the relative quality of the derived item scores. The newly introduced scoring algorithms consistently outperformed scoring algorithms used in the previous literature on scoring many-item best-worst data.},
	pages = {711--729},
	number = {2},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behavior Research Methods},
	author = {Hollis, Geoff},
	date = {2018-04-01},
}

@article{so_measuring_2023,
	title = {Measuring aesthetic preferences of neural style transfer: More precision with the two-alternative-forced-choice task},
	volume = {39},
	url = {https://doi.org/10.1080/10447318.2022.2049081},
	doi = {10.1080/10447318.2022.2049081},
	pages = {755--775},
	number = {4},
	journaltitle = {International Journal of Human–Computer Interaction},
	author = {So, Chaehan},
	date = {2023},
	note = {Publisher: Taylor \& Francis},
}

@article{palmer_visual_2013,
	title = {Visual aesthetics and human preference},
	volume = {64},
	url = {https://doi.org/10.1146/annurev-psych-120710-100504},
	doi = {10.1146/annurev-psych-120710-100504},
	pages = {77--107},
	number = {1},
	journaltitle = {Annual review of psychology},
	author = {Palmer, Stephen E and Schloss, Karen B and Sammartino, Jonathan},
	date = {2013},
	note = {Publisher: Annual Reviews},
}

@inproceedings{vatavu_design_2020,
	location = {Essen, Germany},
	title = {Design space and users’ preferences for smartglasses graphical menus: A vignette study},
	volume = {19},
	url = {10.1145/3428361.3428467},
	doi = {10.1145/3428361.3428467},
	eventtitle = {International Conference on Mobile and Ubiquitous Multimedia},
	pages = {1--12},
	booktitle = {{MUM} '20: Proceedings of the 19th International Conference on Mobile and Ubiquitous Multimedia},
	publisher = {The Association for Computing Machinery},
	author = {Vatavu, Radu-Daniel and Vanderdonckt, Jean},
	date = {2020},
}

@misc{bisson_impact_2024,
	title = {The impact of cross-linguistic orthographic similarity in different learning contexts: incidental vs intentional learning},
	url = {osf.io/2mk7n_v1},
	publisher = {{OSF} Preprints},
	author = {Bisson, Marie-Josee},
	date = {2024-03},
	doi = {10.31219/osf.io/2mk7n},
}

@article{oconnor_intercoder_2020,
	title = {Intercoder reliability in qualitative research: Debates and practical guidelines},
	volume = {19},
	url = {https://doi.org/10.1177/1609406919899220},
	pages = {1609406919899220},
	journaltitle = {International journal of qualitative methods},
	author = {O’Connor, Cliodhna and Joffe, Helene},
	date = {2020},
	note = {Publisher: {SAGE} Publications Sage {CA}: Los Angeles, {CA}},
}

@book{stigler_history_1986,
	location = {Cambridge, Mass.},
	title = {The history of statistics: The measurement of uncertainty before 1900},
	publisher = {Harvard University Press},
	author = {Stigler, Stephen M},
	date = {1986},
}

@book{nunnally_psychometric_1967,
	location = {New York},
	edition = {3},
	title = {Psychometric Theory: Nunnally and Bernstein},
	publisher = {{McGraw}-Hill, Inc},
	author = {Nunnally, Jum C and Bernstein, Ira H},
	date = {1967},
}

@article{robitzsch_package_2017,
	title = {Package ‘sirt’},
	journaltitle = {Computer software]. https://www. maths. bris. ac. uk/R/web/packages/sirt/sirt. pdf},
	author = {Robitzsch, Alexander and Robitzsch, Maintainer Alexander},
	date = {2017},
}
